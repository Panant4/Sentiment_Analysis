{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5647\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import globl\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk import bigrams\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier,Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "from nltk.corpus import wordnet\n",
    "from keras import optimizers\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "path = \"/home/pramod/Downloads/temp/romneycsv.csv\"\n",
    "data2 = pd.read_csv(path)\n",
    "\n",
    "data2 = data2.drop(data2.query('Class!=\"1\" & Class!=\"-1\" & Class!=\"0\"').index)\n",
    "\n",
    "data2.to_csv('/home/pramod/Downloads/temp/romneyupdate.csv', index=False)\n",
    "\n",
    "data1= pd.read_csv('/home/pramod/Downloads/temp/romneyupdate.csv')\n",
    "\n",
    "d = {'date': data1[\"date\"], 'tweet': data1[\"Anootated tweet\"],'Class': data1[\"Class\"]}\n",
    "data = pd.DataFrame(data=d)\n",
    "\n",
    "clean_train_reviews = []\n",
    "\n",
    "for i in xrange(0,len(data)):\n",
    "    clean_train_reviews.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(data[\"tweet\"][i],False,True,False,False)))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "clean_train_reviews1=[]\n",
    "for review in clean_train_reviews:\n",
    "    clean_train_reviews1.append(\" \".join(KaggleWord2VecUtility.useless(review)))\n",
    "    \n",
    "text_clf = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,4),min_df=1,strip_accents='unicode')),\n",
    "                     #('feature_selection', SelectFromModel(svm.LinearSVC(penalty=\"l1\",dual=False))),\n",
    "                     #('feature_selection', SelectFromModel(RandomForestClassifier())),\n",
    "                     ('clf', svm.LinearSVC(class_weight= 'balanced'))\n",
    "                    ])\n",
    "\n",
    "\n",
    "text_clf = text_clf.fit(clean_train_reviews1,data[\"Class\"][0:len(data)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.70      0.76      0.73       631\n",
      "          0       0.41      0.43      0.42       261\n",
      "          1       0.61      0.44      0.51       235\n",
      "\n",
      "avg / total       0.62      0.62      0.61      1127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#vocab= text_clf.named_steps['vect'].vocabulary_\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred=cross_val_predict(estimator=text_clf, X=clean_train_reviews1, y=data[\"Class\"][0:len(data)],cv=StratifiedKFold(10))\n",
    "\n",
    "print(classification_report(data[\"Class\"][0:len(data)], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0 -1 -1 -1 -1  1  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "data3 = pd.read_excel('/home/pramod/Downloads/sample-testdata.xlsx')\n",
    "tweets=np.array(pd.DataFrame(data3[\"Anootated tweet\"]))\n",
    "tweets=tweets[1:]\n",
    "\n",
    "\n",
    "'''data3= pd.read_csv('/home/pramod/Downloads/temp/obamaupdate.csv')\n",
    "#d3 = {'date': data3[\"date\"], 'tweet': data3[\"Anootated tweet\"]}\n",
    "#data_test = pd.DataFrame(data=d3)'''\n",
    "\n",
    "clean_test = []\n",
    "\n",
    "for i in xrange(0,len(tweets)):\n",
    "    clean_test.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(tweets[i],False,True,False,False)))\n",
    "test_labels=text_clf.predict(clean_test)\n",
    "print test_labels[0:10]\n",
    "test_labels=pd.DataFrame(test_labels)\n",
    "\n",
    "#print test_labels\n",
    "test_labels.to_csv('csvfile_romney.csv', encoding='utf-8', index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
